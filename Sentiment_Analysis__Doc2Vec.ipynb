{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis _Doc2Vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMe3M/3TJ4ddRUxLn8hgcxL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kib4PVQOI_7S",
        "colab_type": "text"
      },
      "source": [
        "### Introduction\n",
        "The main goal of this project is to use Doc2Vec to learn representations of entire texts of varying lengths. Doc2Vec is based on the paragraph vectors framework where instead of tokenizing text into words, n-grams or characters, we represent the entire paragraph as a vector.\n",
        "Aftor learning the representations, we will feed the transformed text into a  classifier and perform sentiment analysis of Amazon product reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9UTWmuwK_AO",
        "colab_type": "text"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8No23tTLMTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing Libraries\n",
        "\n",
        "#Machine learning and deep learning\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction import stop_words\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "#pre-processing of text\n",
        "import string\n",
        "import re\n",
        "import json\n",
        "import gzip\n",
        "from urllib.request import urlopen"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR93NO9nLFpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unzipping data\n",
        "!unzip amazon_review_mil.csv.zip\n",
        "reviews_data = 'amazon_review_mil.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-O8Sh9ONSZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "31bebea8-d38e-4f2c-edb7-60f765696b49"
      },
      "source": [
        "#Loading into pandas dataframe\n",
        "df = pd.read_csv(reviews_data)\n",
        "df.columns = ['reviewerID','asin','helpful','reviewText','overall','summary','unixReviewTime','reviewTime','reviewerName','sentiment']\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AH2L9G3DQHHAJ</td>\n",
              "      <td>0000000116</td>\n",
              "      <td>[5, 5]</td>\n",
              "      <td>Interesting Grisham tale of a lawyer that take...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Show me the money!</td>\n",
              "      <td>1019865600</td>\n",
              "      <td>04 27, 2002</td>\n",
              "      <td>chris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A2IIIDRK3PRRZY</td>\n",
              "      <td>0000000116</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>The thumbnail is a shirt.  The product shown i...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Listing is all screwed up</td>\n",
              "      <td>1395619200</td>\n",
              "      <td>03 24, 2014</td>\n",
              "      <td>Helene</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A1TADCM7YWPQ8M</td>\n",
              "      <td>0000000868</td>\n",
              "      <td>[10, 10]</td>\n",
              "      <td>I'll be honest. I work for a large online reta...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Not a Bad Translation</td>\n",
              "      <td>1031702400</td>\n",
              "      <td>09 11, 2002</td>\n",
              "      <td>Joel@AWS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AWGH7V0BDOJKB</td>\n",
              "      <td>0000013714</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>It had all the songs I wanted but I had ordere...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Not the large print</td>\n",
              "      <td>1383177600</td>\n",
              "      <td>10 31, 2013</td>\n",
              "      <td>Barbara Marshall</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A3UTQPQPM4TQO0</td>\n",
              "      <td>0000013714</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>We have many of the old, old issue. But the nu...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>I was disappointed that you would only allow m...</td>\n",
              "      <td>1374883200</td>\n",
              "      <td>07 27, 2013</td>\n",
              "      <td>betty burnett</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID        asin  ...      reviewerName sentiment\n",
              "0   AH2L9G3DQHHAJ  0000000116  ...             chris         1\n",
              "1  A2IIIDRK3PRRZY  0000000116  ...            Helene        -1\n",
              "2  A1TADCM7YWPQ8M  0000000868  ...          Joel@AWS         1\n",
              "3   AWGH7V0BDOJKB  0000013714  ...  Barbara Marshall         1\n",
              "4  A3UTQPQPM4TQO0  0000013714  ...     betty burnett         1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9yQhNWLNynM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7850f04c-0ffb-4df8-b784-3068d5bcaeb7"
      },
      "source": [
        "#Checking class distribution\n",
        "df.sentiment.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    895395\n",
              "-1    104605\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-9ITKYKOVHI",
        "colab_type": "text"
      },
      "source": [
        "### Text Preprocessing\n",
        "Main steps in preprocessing are removing stopwords, punctuations, digits etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm50lR0OOroQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning the reviews' text\n",
        "mystopwords = stop_words.ENGLISH_STOP_WORDS\n",
        "def clean(reviews):\n",
        "    def remove_stops_digits(doc):\n",
        "        doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
        "        doc = \" \".join([token for token in doc.split() if token not in stopwords])\n",
        "        return doc\n",
        "    return [remove_stops_digits(review) for review in reviews]\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPdVnfwFNytM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = clean(df.reviewText[10000:19000])\n",
        "y = df.sentiment[10000:19000]"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc9-x2vAaF46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting data into train, test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 2)\n",
        "\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIMoxCo1id5D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "7eef3d83-7bdf-4cc5-f287-455e8efdc91e"
      },
      "source": [
        "#Learn doc2vec representations\n",
        "train_doc2vec = [TaggedDocument((d), tags=[str(i)]) for i, d in enumerate(X_train)]\n",
        "\n",
        "model = Doc2Vec(vector_size=50, alpha=0.025, min_count=10, dm =1, epochs=30)\n",
        "model.build_vocab(train_doc2vec)\n",
        "model.train(train_doc2vec, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "model.save(\"d2v.model\")\n",
        "print(\"Model Saved\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Saved\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKbp4NnEgtTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8e33514d-f086-4aee-f0df-6d1479f93db5"
      },
      "source": [
        "#After learning vectors, infer vector for train & test data\n",
        "model= Doc2Vec.load(\"d2v.model\")\n",
        "#infer in multiple steps to get a stable representation. \n",
        "train_vectors =  [model.infer_vector(list_of_tokens, steps=50) for list_of_tokens in X_train]\n",
        "test_vectors = [model.infer_vector(list_of_tokens, steps=50) for list_of_tokens in X_test]\n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMmu6D_5iTjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "8bb81c23-8e63-4372-a3e6-1fd70a9b7b34"
      },
      "source": [
        "#Feed the trained vectors into any classifier to train for sentiment analysis. Here I use Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "myclass = LogisticRegression(class_weight=\"balanced\") #because classes are not balanced. \n",
        "myclass.fit(train_vectors, y_train)\n",
        "\n",
        "preds = myclass.predict(test_vectors)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "print(confusion_matrix(test_cats,preds))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.62      0.42       421\n",
            "           1       0.89      0.70      0.78      1829\n",
            "\n",
            "    accuracy                           0.68      2250\n",
            "   macro avg       0.60      0.66      0.60      2250\n",
            "weighted avg       0.78      0.68      0.71      2250\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-a580a4e3debf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_cats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_cats' is not defined"
          ]
        }
      ]
    }
  ]
}